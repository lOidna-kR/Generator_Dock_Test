"""
ì„¤ì • ê´€ë¦¬ ëª¨ë“ˆ

í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì •ì„ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤.
ë¯¼ê°í•œ ì •ë³´ëŠ” .env íŒŒì¼ì— ì €ì¥í•˜ê³ , ì´ ëª¨ë“ˆì„ í†µí•´ ì ‘ê·¼í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
    - í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (python-dotenv ì‚¬ìš©)
    - Vertex AI ì„¤ì • ê´€ë¦¬
    - MCQ ìƒì„± ì„¤ì • (ê°€ì¤‘ì¹˜, Few-shot ì˜ˆì‹œ)
    - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ (Data/Prompts/)
    - ì„¤ì • ê²€ì¦ ë° ë¡œê¹…

ì‚¬ìš© ë°©ë²•:
    1. .env íŒŒì¼ ìƒì„±
       cp .env.example .env
    
    2. .env íŒŒì¼ ìˆ˜ì •
       - GCP_PROJECT_ID: GCP í”„ë¡œì íŠ¸ ID
       - VERTEX_AI_INDEX_ID: Vector Search Index ID
       - VERTEX_AI_ENDPOINT_ID: Vector Search Endpoint ID
       - GCS_BUCKET_NAME: Cloud Storage ë²„í‚· ì´ë¦„
       - GOOGLE_APPLICATION_CREDENTIALS: ì„œë¹„ìŠ¤ ê³„ì • í‚¤ ê²½ë¡œ
    
    3. ì„¤ì • ê²€ì¦
       python -c "from config import validate_config; validate_config()"
       ë˜ëŠ”
       python config.py

ì˜ˆì œ .env íŒŒì¼:
    GCP_PROJECT_ID=yang-first-aid
    VERTEX_AI_INDEX_ID=8376679913746333696
    VERTEX_AI_ENDPOINT_ID=1234567890123456789
    GCS_BUCKET_NAME=rag-cloud-run-test
    GOOGLE_APPLICATION_CREDENTIALS=C:/keys/service-account.json
    LOG_LEVEL=INFO
    LOG_FILE=true
"""

import os
import logging
from typing import Dict, Any, List
from pathlib import Path

# config ëª¨ë“ˆìš© ê°„ë‹¨í•œ ë¡œê±° ì„¤ì •
_config_logger = logging.getLogger("config")
_config_logger.setLevel(logging.INFO)
if not _config_logger.handlers:
    _handler = logging.StreamHandler()
    _handler.setFormatter(logging.Formatter('%(levelname)s - %(message)s'))
    _config_logger.addHandler(_handler)

# python-dotenv ì‚¬ìš© (ì—†ìœ¼ë©´ ì„¤ì¹˜: pip install python-dotenv)
try:
    from dotenv import load_dotenv
    
    # .env íŒŒì¼ ë¡œë“œ
    env_path = Path(__file__).parent / ".env"
    if env_path.exists():
        load_dotenv(dotenv_path=env_path)
        _config_logger.info(f"âœ… .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {env_path}")
    else:
        _config_logger.warning(f"âš ï¸  .env íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. .env.exampleì„ ë³µì‚¬í•˜ì—¬ .envë¥¼ ìƒì„±í•˜ì„¸ìš”.")
except ImportError:
    _config_logger.warning("âš ï¸  python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ ì§ì ‘ ì„¤ì •í•˜ì„¸ìš”.")
    _config_logger.warning("   ì„¤ì¹˜: pip install python-dotenv")


# ==================== Vertex AI ê¸°ë³¸ ì„¤ì • ====================

VERTEX_AI_CONFIG = {
    "project": os.getenv("GCP_PROJECT_ID"),
    "location": os.getenv("GCP_LOCATION", "us-central1"),
    "region": os.getenv("GCP_REGION", "us-central1"),
}


# ==================== ëª¨ë¸ ì„¤ì • ====================


def get_gemini_model_config() -> Dict[str, Any]:
    """
    Gemini ëª¨ë¸ ì„¤ì •ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        Dict[str, Any]: Gemini ëª¨ë¸ ì„¤ì •
            - model_name: Gemini ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: gemini-1.5-flash-002)
    
    Example:
        >>> config = get_gemini_model_config()
        >>> model_name = config["model_name"]
    """
    return {
        "model_name": os.getenv("GEMINI_MODEL_NAME", "gemini-1.5-flash-002"),
    }


def get_retriever_config() -> Dict[str, Any]:
    """
    Retriever ì„¤ì •ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        Dict[str, Any]: Retriever ì„¤ì •
            - embedding_model: ì„ë² ë”© ëª¨ë¸ëª… (ê¸°ë³¸: gemini-embedding-001)
            - embedding_dimensions: ì„ë² ë”© ì°¨ì›ìˆ˜ (ê¸°ë³¸: 3072)
            - index_id: Vertex AI Vector Search Index ID
            - endpoint_id: Vertex AI Endpoint ID
            - gcs_bucket_name: Cloud Storage ë²„í‚· ì´ë¦„
            - k: ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸: 3, Reranking í›„)
            - initial_k: ì´ˆê¸° ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸: 10, Reranking ì „)
            - search_type: ê²€ìƒ‰ íƒ€ì… (ê¸°ë³¸: similarity)
            - similarity_threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸: 0.7)
            - llm_temperature: LLM Temperature (ê¸°ë³¸: 0.7)
            - max_output_tokens: ìµœëŒ€ ì¶œë ¥ í† í° (ê¸°ë³¸: 2048)
            - stream_update: Stream Update ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: false)
    
    Example:
        >>> config = get_retriever_config()
        >>> k = config["k"]
        >>> initial_k = config["initial_k"]
    """
    return {
        "embedding_model": os.getenv("EMBEDDING_MODEL", "gemini-embedding-001"),
        "embedding_dimensions": int(os.getenv("EMBEDDING_DIMENSIONS", "3072")),
        "index_id": os.getenv("VERTEX_AI_INDEX_ID"),
        "endpoint_id": os.getenv("VERTEX_AI_ENDPOINT_ID"),
        "gcs_bucket_name": os.getenv("GCS_BUCKET_NAME"),
        "k": int(os.getenv("RETRIEVAL_K", "3")),  # ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
        "initial_k": int(os.getenv("RETRIEVAL_INITIAL_K", "10")),  # Reranking ì „ ì´ˆê¸° ê²€ìƒ‰ ê°œìˆ˜
        "search_type": os.getenv("SEARCH_TYPE", "similarity"),
        "similarity_threshold": float(os.getenv("SIMILARITY_THRESHOLD", "0.7")),
        "llm_temperature": float(os.getenv("LLM_TEMPERATURE", "0.7")),
        "max_output_tokens": int(os.getenv("MAX_OUTPUT_TOKENS", "2048")),
        "stream_update": os.getenv("STREAM_UPDATE", "false").lower() == "true",
    }


def get_generation_config() -> Dict[str, Any]:
    """
    Generation ì„¤ì • ë°˜í™˜
    
    Returns:
        Generation ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    return {
        "temperature": float(os.getenv("GENERATION_TEMPERATURE", "0.7")),
        "max_tokens": int(os.getenv("GENERATION_MAX_TOKENS", "2048")),
    }


# ==================== ë¬¸ì„œ ì²˜ë¦¬ ì„¤ì • ====================

def get_chunking_config() -> Dict[str, Any]:
    """
    ì²­í‚¹ ì„¤ì • ë°˜í™˜
    
    Returns:
        ì²­í‚¹ ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    return {
        "chunk_size": int(os.getenv("CHUNK_SIZE", "1000")),
        "chunk_overlap": int(os.getenv("CHUNK_OVERLAP", "200")),
    }


CHUNKING_CONFIG = get_chunking_config()


# ==================== íŒŒì¼ ì²˜ë¦¬ ì„¤ì • ====================

FILE_PROCESSING_CONFIG = {
    "supported_extensions": [".pdf", ".txt", ".docx", ".md"],
}


# ==================== ì¶œë ¥ ì„¤ì • ====================

OUTPUT_CONFIG = {
    "max_source_preview": int(os.getenv("MAX_SOURCE_PREVIEW", "300")),
}


# ==================== ë¡œê¹… ì„¤ì • ====================

LOGGING_CONFIG = {
    "level": os.getenv("LOG_LEVEL", "INFO"),
    "console": os.getenv("LOG_CONSOLE", "true").lower() == "true",
    "file_logging": os.getenv("LOG_FILE", "true").lower() == "true",  # ê¸°ë³¸ê°’ trueë¡œ ë³€ê²½
    "format": os.getenv("LOG_FORMAT", "%(asctime)s - %(name)s - %(levelname)s - %(message)s"),
}


def get_logging_config() -> Dict[str, Any]:
    """
    ë¡œê¹… ì„¤ì • ë°˜í™˜
    
    Returns:
        ë¡œê¹… ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    return LOGGING_CONFIG


def get_paths() -> Dict[str, Path]:
    """
    í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì • ë°˜í™˜
    
    Returns:
        ê²½ë¡œ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        - project_root: í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
        - logs: ë¡œê·¸ ë””ë ‰í† ë¦¬ (Logs/)
    """
    project_root = Path(__file__).parent
    return {
        "project_root": project_root,
        "logs": project_root / "Logs",  # ëŒ€ë¬¸ì Logsë¡œ ë³€ê²½
    }


# ==================== ì„¤ì • ê²€ì¦ ====================

def validate_config() -> bool:
    """
    í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ëª¨ë‘ ì„¤ì •ë˜ì—ˆëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
    
    ê²€ì¦ ëŒ€ìƒ:
        - GCP_PROJECT_ID: GCP í”„ë¡œì íŠ¸ ID
        - VERTEX_AI_INDEX_ID: Vector Search Index ID
        - VERTEX_AI_ENDPOINT_ID: Vector Search Endpoint ID
        - GCS_BUCKET_NAME: Cloud Storage ë²„í‚· ì´ë¦„
    
    Returns:
        bool: 
            - True: ëª¨ë“  í•„ìˆ˜ ì„¤ì • ì¡´ì¬
            - False: ëˆ„ë½ëœ ì„¤ì • ìˆìŒ
    
    Example:
        >>> if not validate_config():
        ...     raise ValueError("ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”!")
    """
    required_vars = [
        "GCP_PROJECT_ID",
        "VERTEX_AI_INDEX_ID",
        "VERTEX_AI_ENDPOINT_ID",
        "GCS_BUCKET_NAME",
    ]
    
    missing = []
    for var in required_vars:
        value = os.getenv(var)
        if not value or value == f"your-{var.lower().replace('_', '-')}-here":
            missing.append(var)
    
    if missing:
        _config_logger.error("=" * 60)
        _config_logger.error("âŒ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì˜¤ë¥˜")
        _config_logger.error("=" * 60)
        _config_logger.error(f"ëˆ„ë½ëœ í™˜ê²½ ë³€ìˆ˜: {', '.join(missing)}")
        _config_logger.error("í•´ê²° ë°©ë²•:")
        _config_logger.error("1. .env.exampleì„ ë³µì‚¬í•˜ì—¬ .env íŒŒì¼ ìƒì„±")
        _config_logger.error("   cp .env.example .env")
        _config_logger.error("2. .env íŒŒì¼ì„ ì—´ì–´ì„œ ì‹¤ì œ ê°’ìœ¼ë¡œ ìˆ˜ì •")
        _config_logger.error(f"   í¸ì§‘: {missing[0]}=your-actual-value")
        _config_logger.error("3. ê° ê°’ì„ í™•ì¸í•˜ëŠ” ë°©ë²•ì€ .env.example ì£¼ì„ ì°¸ê³ ")
        _config_logger.error("=" * 60)
        return False
    
    _config_logger.info("âœ… ëª¨ë“  í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return True


def log_config_status():
    """
    í˜„ì¬ ì„¤ì • ìƒíƒœë¥¼ ë¡œê¹…í•©ë‹ˆë‹¤ (ë¯¼ê°ì •ë³´ ì œì™¸).
    
    ë””ë²„ê¹…ì´ë‚˜ ì„¤ì • í™•ì¸ìš©ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Example:
        >>> from config import log_config_status
        >>> log_config_status()
    """
    separator = "=" * 60
    _config_logger.info(separator)
    _config_logger.info("í˜„ì¬ ì„¤ì • ìƒíƒœ")
    _config_logger.info(separator)
    
    # í”„ë¡œì íŠ¸ ì •ë³´
    project_id = os.getenv("GCP_PROJECT_ID", "ë¯¸ì„¤ì •")
    _config_logger.info(f"ğŸ“Œ í”„ë¡œì íŠ¸: {project_id[:20]}...")
    
    # ëª¨ë¸ ì„¤ì •
    _config_logger.info("ğŸ¤– ëª¨ë¸:")
    _config_logger.info(f"  - Gemini: {os.getenv('GEMINI_MODEL_NAME', 'gemini-1.5-flash-002')}")
    _config_logger.info(f"  - Embedding: {os.getenv('EMBEDDING_MODEL', 'gemini-embedding-001')}")
    _config_logger.info(f"  - Embedding ì°¨ì›: {os.getenv('EMBEDDING_DIMENSIONS', '3072')}")
    
    # Retrieval ì„¤ì •
    _config_logger.info("ğŸ” Retrieval:")
    _config_logger.info(f"  - K: {os.getenv('RETRIEVAL_K', '3')}")
    _config_logger.info(f"  - Initial K: {os.getenv('RETRIEVAL_INITIAL_K', '10')}")
    _config_logger.info(f"  - Search Type: {os.getenv('SEARCH_TYPE', 'similarity')}")
    _config_logger.info(f"  - Threshold: {os.getenv('SIMILARITY_THRESHOLD', '0.7')}")
    
    # LLM ì„¤ì •
    _config_logger.info("âš™ï¸  LLM:")
    _config_logger.info(f"  - Temperature: {os.getenv('LLM_TEMPERATURE', '0.7')}")
    _config_logger.info(f"  - Max Tokens: {os.getenv('MAX_OUTPUT_TOKENS', '2048')}")
    
    # ë¡œê¹… ì„¤ì •
    _config_logger.info("ğŸ“ ë¡œê¹…:")
    _config_logger.info(f"  - Level: {os.getenv('LOG_LEVEL', 'INFO')}")
    _config_logger.info(f"  - Console: {os.getenv('LOG_CONSOLE', 'true')}")
    _config_logger.info(f"  - File: {os.getenv('LOG_FILE', 'true')}")
    
    _config_logger.info(separator)


# ==================== MCQ ê´€ë ¨ ì„¤ì • ====================


def get_mcq_generation_config() -> Dict[str, Any]:
    """
    MCQ ìƒì„± ì„¤ì •ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        Dict[str, Any]: MCQ ìƒì„± ì„¤ì •
            - random_sample_max: ëœë¤ ìƒ˜í”Œë§ ìµœëŒ€ ê°œìˆ˜ (ê¸°ë³¸: 1000)
            - few_shot_max_examples: Few-shot ì˜ˆì‹œ ìµœëŒ€ ê°œìˆ˜ (ê¸°ë³¸: 1)
            - few_shot_folder_path: Few-shot í´ë” ê²½ë¡œ (ê¸°ë³¸: Data/Few_Shot)
            - part_weights: Partë³„ ê°€ì¤‘ì¹˜ (êµì¬ ë¹„ì¤‘ ë°˜ì˜)
            - category_weights: ì¹´í…Œê³ ë¦¬ë³„ ê°€ì¤‘ì¹˜ (ë¬¸ì œ í˜•íƒœ ë¹„ìœ¨)
    
    Example:
        >>> config = get_mcq_generation_config()
        >>> part_weights = config["part_weights"]
        >>> category_weights = config["category_weights"]
    """
    return {
        "random_sample_max": int(os.getenv("MCQ_RANDOM_SAMPLE_MAX", "1000")),
        "few_shot_max_examples": int(os.getenv("MCQ_FEW_SHOT_MAX_EXAMPLES", "1")),  # 1ê°œ ì˜ˆì‹œ (ëª…í™•í•œ í˜•ì‹ ì§€ì‹œ)
        "few_shot_folder_path": os.getenv("MCQ_FEW_SHOT_FOLDER_PATH", "Data/Few_Shot"),
        "max_context_docs": int(os.getenv("MCQ_MAX_CONTEXT_DOCS", "3")),
        
        # Partë³„ ê°€ì¤‘ì¹˜ (ì „ì²´ ë¹„ìœ¨, ì‹¤ì œ ë©”íƒ€ë°ì´í„° í˜•ì‹ ì‚¬ìš©)
        # ì£¼ì˜: ë©”íƒ€ë°ì´í„°ëŠ” ì§§ì€ í˜•ì‹ ("ì´ë¡ ", "ë²•ë ¹", "ê°ë¡ ")
        "part_weights": {
            "ì´ë¡ ": 22.5,      # ì „ì²´ 22.5% - ê¸°ì´ˆ ì´ë¡ 
            "ë²•ë ¹": 10,        # ì „ì²´ 10% - ë²•ê·œ
            "ê°ë¡ ": 67.5,      # ì „ì²´ 67.5% - ê°ë¡  (í•˜ìœ„ ì£¼ì œë“¤ë¡œ ë¶„ë°°ë¨)
        },
        
        # Chapterë³„ ê°€ì¤‘ì¹˜ (ì „ì²´ ë¹„ìœ¨ë¡œ ì§ì ‘ ì§€ì •)
        # ê°ë¡ ì˜ Chapterë“¤ì„ Partì™€ ë™ì¼í•œ ë ˆë²¨ì—ì„œ ê°€ì¤‘ì¹˜ ì ìš©
        "chapter_weights": {
            "ì´ë¡ ": {
                "ì‘ê¸‰ì˜ë£Œì²´ê³„ì˜ê°œìš”": 4.5,       # ì´ë¡  22.5%ë¥¼ 5ê°œ Chapterë¡œ ê· ë“± ë¶„ë°°
                "í™˜ìì´ì†¡ë°êµ¬ê¸‰ì°¨ìš´ìš©": 4.5,
                "ëŒ€ëŸ‰ì¬ë‚œ": 4.5,
                "í™˜ìí‰ê°€": 4.5,
                "êµ¬ê¸‰ì¥ë¹„": 4.5,
                # í•©ê³„: 22.5% (ì´ë¡  ì „ì²´)
            },
            "ë²•ë ¹": {
                "êµ¬ì¡°êµ¬ê¸‰ì—ê´€í•œë²•ë¥ ": 5,         # ë²•ë ¹ 10%ë¥¼ 2ê°œ Chapterë¡œ ê· ë“± ë¶„ë°°
                "ì‘ê¸‰ì˜ë£Œì—ê´€í•œë²•ë¥ ": 5,
                # í•©ê³„: 10% (ë²•ë ¹ ì „ì²´)
            },
            "ê°ë¡ ": {
                "ì „ë¬¸ì‹¬ì¥ì†Œìƒìˆ ": 25,      # ì „ì²´ 25%
                "ì „ë¬¸ì™¸ìƒì²˜ì¹˜ìˆ ": 22.5,    # ì „ì²´ 22.5%
                "ë‚´ê³¼ì‘ê¸‰": 15,             # ì „ì²´ 15%
                "íŠ¹ìˆ˜ì‘ê¸‰": 5,              # ì „ì²´ 5%
                # í•©ê³„: 67.5% (ê°ë¡  ì „ì²´)
            }
        },
        
        # ì£¼ì œë³„ ì¹´í…Œê³ ë¦¬ ê°€ì¤‘ì¹˜ (ë¬¸ì œ í˜•íƒœ ë¹„ìœ¨) - Few_Shot ë¶„ì„ ê²°ê³¼ ë°˜ì˜
        "topic_category_weights": {
            "ì´ë¡ ": {
                "SIMPLE": 0.45,      # 45% (ê¸°ì´ˆ ì´ë¡ ì€ ë‹¨ìˆœí˜• ìœ„ì£¼)
                "MULTIPLE": 0.15,    # 15% (ë³µìˆ˜ ì„ íƒí˜• ì ìŒ)
                "CASE_BASED": 0.30, # 30% (ì¼€ì´ìŠ¤ ê¸°ë°˜í˜•)
                "IMAGE_BASED": 0.10, # 15% (ì´ë¯¸ì§€ ê¸°ë°˜)
                "ECG_BASED": 0.00,  # 0% (ì‹¬ì „ë„ ê´€ë ¨ ì ìŒ)
            },
            # ì´ë¡  - Chapter ë‹¨ìœ„ ê°€ì¤‘ì¹˜ (Part ê°€ì¤‘ì¹˜ ë³µì œ, í•„ìš” ì‹œ ì±•í„°ë³„ë¡œ ì¡°ì • ê°€ëŠ¥)
            "ì‘ê¸‰ì˜ë£Œì²´ê³„ì˜ê°œìš”": {
                "SIMPLE": 0.45,
                "MULTIPLE": 0.15,
                "CASE_BASED": 0.30,
                "IMAGE_BASED": 0.10,
                "ECG_BASED": 0.00,
            },
            "í™˜ìì´ì†¡ë°êµ¬ê¸‰ì°¨ìš´ìš©": {
                "SIMPLE": 0.45,
                "MULTIPLE": 0.15,
                "CASE_BASED": 0.30,
                "IMAGE_BASED": 0.10,
                "ECG_BASED": 0.00,
            },
            "ëŒ€ëŸ‰ì¬ë‚œ": {
                "SIMPLE": 0.45,
                "MULTIPLE": 0.15,
                "CASE_BASED": 0.30,
                "IMAGE_BASED": 0.10,
                "ECG_BASED": 0.00,
            },
            "í™˜ìí‰ê°€": {
                "SIMPLE": 0.45,
                "MULTIPLE": 0.15,
                "CASE_BASED": 0.30,
                "IMAGE_BASED": 0.10,
                "ECG_BASED": 0.00,
            },
            "êµ¬ê¸‰ì¥ë¹„": {
                "SIMPLE": 0.45,
                "MULTIPLE": 0.15,
                "CASE_BASED": 0.30,
                "IMAGE_BASED": 0.10,
                "ECG_BASED": 0.00,
            },
            "ë²•ë ¹": {
                "SIMPLE": 0.60,      # 60% (ë²•ê·œëŠ” ë‹¨ìˆœí˜• ìœ„ì£¼)
                "MULTIPLE": 0.20,    # 20% (ë³µìˆ˜ ì„ íƒí˜•)
                "CASE_BASED": 0.20, # 20% (ì¼€ì´ìŠ¤ ê¸°ë°˜í˜•)
                "IMAGE_BASED": 0.00, # 0% (ì´ë¯¸ì§€ ê¸°ë°˜ ì ìŒ)
                "ECG_BASED": 0.00,  # 0% (ì‹¬ì „ë„ ê´€ë ¨ ì—†ìŒ)
            },
            # ê°ë¡  Part ì „ì²´ ì„ íƒ ì‹œ ì‚¬ìš©í•  ëŒ€í‘œ ê°€ì¤‘ì¹˜ (í•˜ìœ„ ì±•í„° ë¹„ìœ¨ ê°€ì¤‘ í‰ê· )
            "ê°ë¡ ": {
                "SIMPLE": 0.20,
                "MULTIPLE": 0.1167,
                "CASE_BASED": 0.3130,
                "IMAGE_BASED": 0.1111,
                "ECG_BASED": 0.2593,
            },
            # ë²•ë ¹ - Chapter ë‹¨ìœ„ ê°€ì¤‘ì¹˜ (Part ê°€ì¤‘ì¹˜ ë³µì œ, í•„ìš” ì‹œ ì±•í„°ë³„ë¡œ ì¡°ì • ê°€ëŠ¥)
            "êµ¬ì¡°êµ¬ê¸‰ì—ê´€í•œë²•ë¥ ": {
                "SIMPLE": 0.60,
                "MULTIPLE": 0.20,
                "CASE_BASED": 0.20,
                "IMAGE_BASED": 0.00,
                "ECG_BASED": 0.00,
            },
            "ì‘ê¸‰ì˜ë£Œì—ê´€í•œë²•ë¥ ": {
                "SIMPLE": 0.60,
                "MULTIPLE": 0.20,
                "CASE_BASED": 0.20,
                "IMAGE_BASED": 0.00,
                "ECG_BASED": 0.00,
            },
            "ì „ë¬¸ì‹¬ì¥ì†Œìƒìˆ ": {
                "SIMPLE": 0.05,      # 5% (ë‹¨ìˆœí˜• ì ìŒ)
                "MULTIPLE": 0.05,    # 5% (ë³µìˆ˜ ì„ íƒí˜• ì ìŒ)
                "CASE_BASED": 0.20, # 20% (ì¼€ì´ìŠ¤ ê¸°ë°˜í˜•)
                "IMAGE_BASED": 0.00, # 0% (ì´ë¯¸ì§€ ê¸°ë°˜)
                "ECG_BASED": 0.70,  # 70% (ì‹¬ì „ë„ ê´€ë ¨ ê°•í™”)
            },
            "ì „ë¬¸ì™¸ìƒì²˜ì¹˜ìˆ ": {
                "SIMPLE": 0.30,      # 25% (ë‹¨ìˆœí˜•)
                "MULTIPLE": 0.15,    # 15% (ë³µìˆ˜ ì„ íƒí˜•)
                "CASE_BASED": 0.35, # 35% (ì¼€ì´ìŠ¤ ê¸°ë°˜í˜• ê°•í™”)
                "IMAGE_BASED": 0.20, # 20% (ì´ë¯¸ì§€ ê¸°ë°˜)
                "ECG_BASED": 0.00,  # 5% (ì‹¬ì „ë„ ê´€ë ¨ ì ìŒ)
            },
            "ë‚´ê³¼ì‘ê¸‰": {
                "SIMPLE": 0.25,      # 25% (ë‹¨ìˆœí˜•)
                "MULTIPLE": 0.15,    # 15% (ë³µìˆ˜ ì„ íƒí˜•)
                "CASE_BASED": 0.45, # 40% (ì¼€ì´ìŠ¤ ê¸°ë°˜í˜• ê°•í™”)
                "IMAGE_BASED": 0.15, # 15% (ì´ë¯¸ì§€ ê¸°ë°˜)
                "ECG_BASED": 0.00,  # 5% (ì‹¬ì „ë„ ê´€ë ¨ ì ìŒ)
            },
            "íŠ¹ìˆ˜ì‘ê¸‰": {
                "SIMPLE": 0.35,      # 30% (ë‹¨ìˆœí˜•)
                "MULTIPLE": 0.20,    # 20% (ë³µìˆ˜ ì„ íƒí˜•)
                "CASE_BASED": 0.30, # 30% (ì¼€ì´ìŠ¤ ê¸°ë°˜í˜•)
                "IMAGE_BASED": 0.15, # 15% (ì´ë¯¸ì§€ ê¸°ë°˜)
                "ECG_BASED": 0.00,  # 5% (ì‹¬ì „ë„ ê´€ë ¨ ì ìŒ)
            }
        },
        
        # ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ ê°€ì¤‘ì¹˜ (ì£¼ì œë³„ ì„¤ì •ì´ ì—†ì„ ë•Œ ì‚¬ìš©)
        "default_category_weights": {
            "SIMPLE": 0.25,      # 25% (ë‹¨ìˆœ ì„ íƒí˜•)
            "MULTIPLE": 0.20,    # 20% (ë³µìˆ˜ ì„ íƒí˜•: ã‰ ã‰¡ã‰¢ ëª¨ë‘ ê³ ë¥´ì‹œì˜¤)
            "CASE_BASED": 0.25,  # 25% (ì¼€ì´ìŠ¤ ê¸°ë°˜í˜•)
            "IMAGE_BASED": 0.20, # 20% (ì´ë¯¸ì§€/ê·¸ë˜í”„ ì°¸ì¡°í˜•)
            "ECG_BASED": 0.10,   # 10% (ì‹¬ì „ë„ ê´€ë ¨í˜•)
        }
    }


def get_category_weights_by_topic(topic_name: str) -> Dict[str, float]:
    """
    ì£¼ì œë³„ ì¹´í…Œê³ ë¦¬ ê°€ì¤‘ì¹˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        topic_name: ì£¼ì œ ì´ë¦„ (ì´ë¡ , ë²•ë ¹, ì „ë¬¸ì‹¬ì¥ì†Œìƒìˆ , ì „ë¬¸ì™¸ìƒì²˜ì¹˜ìˆ , ë‚´ê³¼ì‘ê¸‰, íŠ¹ìˆ˜ì‘ê¸‰)
    
    Returns:
        Dict[str, float]: ì¹´í…Œê³ ë¦¬ë³„ ê°€ì¤‘ì¹˜
    """
    config = get_mcq_generation_config()
    topic_weights = config.get("topic_category_weights", {})
    
    # ì£¼ì œë³„ ê°€ì¤‘ì¹˜ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    return topic_weights.get(topic_name, config.get("default_category_weights", {}))


def get_mcq_types() -> Dict[str, Any]:
    """
    MCQ ìœ í˜• ì„¤ì •ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Few-shot ì˜ˆì‹œë¥¼ Data/Few_Shot/ í´ë”ì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Returns:
        Dict[str, Any]: MCQ ìœ í˜• ë”•ì…”ë„ˆë¦¬
            - MCQ_GENERAL: ì¼ë°˜ MCQ ì„¤ì •
                - name: ìœ í˜• ì´ë¦„
                - instruction: ìƒì„± ì§€ì¹¨
                - few_shot_examples: ì „ì²´ Few-shot ì˜ˆì‹œ
                - category_examples: ì¹´í…Œê³ ë¦¬ë³„ ì˜ˆì‹œ
    
    Example:
        >>> mcq_types = get_mcq_types()
        >>> general_config = mcq_types["MCQ_GENERAL"]
        >>> examples = general_config["few_shot_examples"]
    """
    from Utils.few_shot import load_few_shot_examples_from_folder
    
    config = get_mcq_generation_config()
    folder_path = config["few_shot_folder_path"]
    
    # ì¹´í…Œê³ ë¦¬ ì •ì˜ (ìƒˆë¡œìš´ íŒŒì¼ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
    categories = {
        "SIMPLE": "ë‹¨ìˆœí˜•",
        "MULTIPLE": "ë³µìˆ˜í˜•", 
        "CASE_BASED": "ì¼€ì´ìŠ¤í˜•",
        "IMAGE_BASED": "ì´ë¯¸ì§€í˜•",
        "ECG_BASED": "ì‹¬ì „ë„í˜•"
    }
    
    all_examples = []
    category_examples = {}
    
    try:
        few_shot_dict = load_few_shot_examples_from_folder(folder_path)
        
        # ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ ë¡œë“œ (ìƒˆë¡œìš´ íŒŒì¼ëª… êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
        file_mapping = {
            "SIMPLE": "Single_Type",
            "MULTIPLE": "Multiple_Type",
            "CASE_BASED": "Case_Type", 
            "IMAGE_BASED": "Image_Type",
            "ECG_BASED": "ECG_Type"
        }
        
        for cat_key, cat_name in categories.items():
            file_name = file_mapping.get(cat_key)
            if file_name and file_name in few_shot_dict:
                examples = few_shot_dict[file_name]
                category_examples[cat_key] = examples
                all_examples.extend(examples)
        
        # MCQ_GENERALë„ ìˆìœ¼ë©´ ì¶”ê°€ (í˜¸í™˜ì„±)
        if "MCQ_GENERAL" in few_shot_dict:
            general_examples = few_shot_dict["MCQ_GENERAL"]
            all_examples.extend(general_examples)
        
        if not all_examples:
            raise ValueError("Few-shot ì˜ˆì‹œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ê°„ê²°í•œ ë¡œë“œ ì™„ë£Œ ë©”ì‹œì§€
        _config_logger.info(f"âœ“ Few-shot ë¡œë“œ ì™„ë£Œ ({len(all_examples)}ê°œ, {len(category_examples)} ì¹´í…Œê³ ë¦¬)")
        
    except (FileNotFoundError, Exception) as e:
        _config_logger.error(f"âŒ Few-shot í´ë” ë¡œë“œ ì‹¤íŒ¨: {e}")
        _config_logger.warning(f"   ê¸°ë³¸ ì˜ˆì‹œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        # Fallback: ê¸°ë³¸ ì˜ˆì‹œ
        all_examples = [
            {
                "question": "ì‘ê¸‰ì˜ë£Œì²´ê³„ì˜ ì£¼ìš” êµ¬ì„±ìš”ì†ŒëŠ”?",
                "options": [
                    "119 êµ¬ê¸‰ëŒ€",
                    "ì‘ê¸‰ì˜ë£Œê¸°ê´€",
                    "ì˜ë£Œì§€ë„",
                    "ëª¨ë‘ í¬í•¨"
                ],
                "answer_index": 4,
                "explanation": "ì‘ê¸‰ì˜ë£Œì²´ê³„ëŠ” 119 êµ¬ê¸‰ëŒ€, ì‘ê¸‰ì˜ë£Œê¸°ê´€, ì˜ë£Œì§€ë„ ë“± ëª¨ë“  ìš”ì†Œê°€ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            }
        ]
        category_examples = {}
    
    return {
        "MCQ_GENERAL": {
            "name": "MCQ_GENERAL",
            "instruction": (
                "êµì¬ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ 4ì§€ì„ ë‹¤í˜• ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”. "
                "âš ï¸ ì¤‘ìš”: Few-shot ì˜ˆì‹œì™€ ë™ì¼í•œ í˜•ì‹(ì§ˆë¬¸ êµ¬ì¡°, ë³´ê¸° ìŠ¤íƒ€ì¼, í•´ì„¤ ë°©ì‹)ìœ¼ë¡œ ì‘ì„±í•˜ë˜, "
                "ë‚´ìš©ì€ ë°˜ë“œì‹œ êµì¬ì—ì„œ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤. "
                "ì§ˆë¬¸ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ì´ì–´ì•¼ í•˜ë©°, ë³´ê¸°ëŠ” ì„œë¡œ êµ¬ë¶„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì •ë‹µ í•´ì„¤ì€ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”."
            ),
            "few_shot_examples": all_examples,
            "category_examples": category_examples,  # ì¹´í…Œê³ ë¦¬ë³„ ì˜ˆì‹œ ì¶”ê°€
        }
    }


def get_prompt_templates() -> Dict[str, str]:
    """
    MCQ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë°˜í™˜
    
    í”„ë¡¬í”„íŠ¸ëŠ” Data/Prompts/ í´ë”ì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ë¡œë“œë©ë‹ˆë‹¤.
    ë²„ì „ ê´€ë¦¬ì™€ A/B í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ íŒŒì¼ë¡œ ë¶„ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.
    
    Returns:
        í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë”•ì…”ë„ˆë¦¬
        - mcq_generation_system: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        - mcq_generation_human_retriever: Retriever ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ (ì£¼ì œ ê¸°ë°˜ ìƒì„±)
    
    Example:
        >>> templates = get_prompt_templates()
        >>> system_prompt = templates["mcq_generation_system"]
    """
    prompt_dir = Path(__file__).parent / "Data" / "Prompts"
    
    try:
        # í”„ë¡¬í”„íŠ¸ íŒŒì¼ì—ì„œ ë¡œë“œ
        system_prompt = (prompt_dir / "system_prompt.txt").read_text(encoding="utf-8")
        human_retriever = (prompt_dir / "retriever_prompt.txt").read_text(encoding="utf-8")
        
        _config_logger.debug("í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ ì™„ë£Œ (íŒŒì¼ì—ì„œ)")
        
        return {
            "mcq_generation_system": system_prompt,
            "mcq_generation_human_retriever": human_retriever,
        }
        
    except FileNotFoundError as e:
        _config_logger.warning(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}. ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
        
        # Fallback: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (ê°„ë‹¨ ë²„ì „)
        return {
            "mcq_generation_system": (
                "ë‹¹ì‹ ì€ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ êµì¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ "
                "4ì§€ì„ ë‹¤í˜• ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
            ),
            "mcq_generation_human_retriever": (
                "êµì¬ ë‚´ìš©:\n{context}\n\n"
                "ì£¼ì œ: {question}\n\n"
                "ì§€ì¹¨:\n{instruction}\n\n"
                "{format_instructions}"
            ),
        }


# ==================== êµì¬ êµ¬ì¡° ì„¤ì • ====================


def get_textbook_structure() -> Dict[str, List[str]]:
    """
    êµì¬ì˜ Partì™€ Chapter êµ¬ì¡° ë°˜í™˜
    
    ì¶œì²˜: 2026_ì–‘ìŠ¹ì•„_ì‘ê¸‰ì²˜ì¹˜í•™ê°œë¡ _ëª©ì°¨.pdf
    
    ì¤‘ìš”: ì‹¤ì œ ë©”íƒ€ë°ì´í„° í˜•ì‹ ì‚¬ìš© (ì§§ì€ í˜•ì‹)
    - Part: "ì´ë¡ ", "ë²•ë ¹", "ê°ë¡ "
    - Chapter: "ì „ë¬¸ì‹¬ì¥ì†Œìƒìˆ ", "ì „ë¬¸ì™¸ìƒì²˜ì¹˜ìˆ " ë“±
    
    Returns:
        êµì¬ êµ¬ì¡° ë”•ì…”ë„ˆë¦¬
        - Key: Part ì´ë¦„ (ì‹¤ì œ ë©”íƒ€ë°ì´í„° í˜•ì‹)
        - Value: Chapter ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (ì‹¤ì œ ë©”íƒ€ë°ì´í„° í˜•ì‹)
    
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> structure = get_textbook_structure()
        >>> generator.generate_mcq(topics_hierarchical=structure)
    """
    return {
        "ì´ë¡ ": [
            "ì‘ê¸‰ì˜ë£Œì²´ê³„ì˜ê°œìš”",
            "í™˜ìì´ì†¡ë°êµ¬ê¸‰ì°¨ìš´ìš©",
            "ëŒ€ëŸ‰ì¬ë‚œ",
            "í™˜ìí‰ê°€",
            "êµ¬ê¸‰ì¥ë¹„",
        ],
        "ë²•ë ¹": [
            "êµ¬ì¡°êµ¬ê¸‰ì—ê´€í•œë²•ë¥ ",
            "ì‘ê¸‰ì˜ë£Œì—ê´€í•œë²•ë¥ ",
        ],
        "ê°ë¡ ": [
            "ì „ë¬¸ì‹¬ì¥ì†Œìƒìˆ ",
            "ì „ë¬¸ì™¸ìƒì²˜ì¹˜ìˆ ",
            "ë‚´ê³¼ì‘ê¸‰",
            "íŠ¹ìˆ˜ì‘ê¸‰",
        ],
    }


# ì „ì—­ ìƒìˆ˜ë¡œ ë…¸ì¶œ
TEXTBOOK_STRUCTURE = get_textbook_structure()


# ==================== ì´ˆê¸°í™” ì‹œ ìë™ ê²€ì¦ ====================

if __name__ == "__main__":
    # config.pyë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ë©´ ì„¤ì • ê²€ì¦
    _config_logger.info("ğŸ” ì„¤ì • ê²€ì¦ ì¤‘...")
    
    if validate_config():
        log_config_status()
        
        # êµì¬ êµ¬ì¡° ì¶œë ¥
        _config_logger.info("=" * 60)
        _config_logger.info("ğŸ“š êµì¬ êµ¬ì¡°")
        _config_logger.info("=" * 60)
        structure = get_textbook_structure()
        for part, chapters in structure.items():
            _config_logger.info(f"{part}")
            for chapter in chapters:
                _config_logger.info(f"  - {chapter}")
        _config_logger.info("=" * 60)
    else:
        _config_logger.error("ğŸ’¡ .env íŒŒì¼ ì„¤ì • í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")

