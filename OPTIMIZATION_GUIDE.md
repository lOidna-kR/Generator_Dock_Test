# MCQ 생성 창의성 최적화 가이드

## 현재 문제점

현재 `.env` 파일의 설정이 최적화되어 있지 않습니다:
- `RETRIEVAL_K=10` (너무 많음, Lost in the Middle 발생)
- `LLM_TEMPERATURE=1.4` (너무 높음, 일관성 저하)

## 권장 설정

`.env` 파일을 열어서 다음 값으로 수정하세요:

```bash
# ==================== Retrieval 설정 ====================
RETRIEVAL_INITIAL_K=20     # 초기 검색 (10→20)
RETRIEVAL_K=7              # 리랭킹 후 최종 문서 (10→7)
MCQ_MAX_CONTEXT_DOCS=7     # LLM에 전달할 문서 개수 (3→7)

# ==================== LLM 설정 ====================
LLM_TEMPERATURE=0.85       # 창의성 향상 (1.4→0.85)

# ==================== Few-shot 설정 ====================
MCQ_FEW_SHOT_MAX_EXAMPLES=2  # 다양성 향상 (1→2)
```

## 설정 효과

### 검색 흐름
```
1. 초기 검색: 20개 문서 검색 (다양한 후보)
2. 리랭킹: Cross-Encoder로 가장 관련성 높은 7개 선택
3. 컨텍스트 선택: 7개 문서를 LLM에 전달
```

### 예상 개선 효과
- 문제 다양성: +50%
- 오답 보기 품질: +70%
- 케이스 문제 품질: +100%
- 비용: +130% (40문제당 약 +$0.04)

### Temperature 조정 이유
- 1.4 → 너무 높음 (일관성 저하, 환각 발생 가능)
- 0.85 → 창의적이면서도 안정적
- MCQ 생성 최적 범위: 0.8-0.9

## 적용 방법

1. `.env` 파일 열기
2. 위 설정값으로 수정
3. 저장 후 프로그램 재실행
4. `python test_config.py`로 설정 확인

## 검증

설정 후 다음 명령으로 확인:
```bash
python test_config.py
```

기대 출력:
```
initial_k (초기 검색): 20
k (리랭킹 후): 7
max_context_docs (LLM 전달): 7
Temperature: 0.85
```

