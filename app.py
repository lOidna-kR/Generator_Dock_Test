"""Streamlit ê¸°ë°˜ Ask/Forge í†µí•© UI."""

from __future__ import annotations

import random
import re
from collections import Counter
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import streamlit as st

from Core import AskMode, ForgeMode
from Utils import setup_logging
from config import (
    get_category_weights_by_topic,
    get_mcq_generation_config,
    get_textbook_structure,
    validate_config,
)


FORGE_TOPIC_ALIASES: Dict[str, List[str]] = {
    "mock_exam": ["ë™í˜•ëª¨ì˜ê³ ì‚¬", "ëª¨ì˜ê³ ì‚¬", "ëª¨ì˜", "mock"],
    "ì´ë¡ ": ["ì´ë¡ "],
    "ë²•ë ¹": ["ë²•ë ¹"],
    "ê°ë¡ ": ["ê°ë¡ "],
    "ì „ë¬¸ì‹¬ì¥ì†Œìƒìˆ ": ["ì „ë¬¸ì‹¬ì¥ì†Œìƒìˆ ", "ì‹¬ì¥ì†Œìƒìˆ ", "ì‹¬ì¥", "acls"],
    "ì „ë¬¸ì™¸ìƒì²˜ì¹˜ìˆ ": ["ì „ë¬¸ì™¸ìƒì²˜ì¹˜ìˆ ", "ì™¸ìƒì²˜ì¹˜ìˆ ", "ì™¸ìƒ"],
    "ë‚´ê³¼ì‘ê¸‰": ["ë‚´ê³¼ì‘ê¸‰", "ë‚´ê³¼"],
    "íŠ¹ìˆ˜ì‘ê¸‰": ["íŠ¹ìˆ˜ì‘ê¸‰", "íŠ¹ìˆ˜"],
}

FORGE_TOPIC_TYPES: Dict[str, str] = {
    "mock_exam": "mock_exam",
    "ì´ë¡ ": "part",
    "ë²•ë ¹": "part",
    "ê°ë¡ ": "part",
    "ì „ë¬¸ì‹¬ì¥ì†Œìƒìˆ ": "chapter",
    "ì „ë¬¸ì™¸ìƒì²˜ì¹˜ìˆ ": "chapter",
    "ë‚´ê³¼ì‘ê¸‰": "chapter",
    "íŠ¹ìˆ˜ì‘ê¸‰": "chapter",
}

FORGE_TOPIC_DISPLAY_NAMES: Dict[str, str] = {
    "mock_exam": "ë™í˜•ëª¨ì˜ê³ ì‚¬",
    "ì´ë¡ ": "ì´ë¡ ",
    "ë²•ë ¹": "ë²•ë ¹",
    "ê°ë¡ ": "ê°ë¡ ",
    "ì „ë¬¸ì‹¬ì¥ì†Œìƒìˆ ": "ì „ë¬¸ì‹¬ì¥ì†Œìƒìˆ ",
    "ì „ë¬¸ì™¸ìƒì²˜ì¹˜ìˆ ": "ì „ë¬¸ì™¸ìƒì²˜ì¹˜ìˆ ",
    "ë‚´ê³¼ì‘ê¸‰": "ë‚´ê³¼ì‘ê¸‰",
    "íŠ¹ìˆ˜ì‘ê¸‰": "íŠ¹ìˆ˜ì‘ê¸‰",
}


@st.cache_resource(show_spinner=False)
def load_app_components() -> Tuple[AskMode, ForgeMode, Dict[str, Any], Dict[str, List[str]], Any]:
    """Streamlit ì•±ì—ì„œ ì‚¬ìš©í•  Ask/Forge ì»´í¬ë„ŒíŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""

    if not validate_config():
        raise RuntimeError("í™˜ê²½ ë³€ìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

    logger = setup_logging("Streamlit.App")
    ask_mode = AskMode(logger=logger)

    try:
        forge_mode = ForgeMode(
            vector_store=ask_mode.vector_store,
            llm=ask_mode.llm,
            logger=logger,
        )
    except Exception as exc:  # pragma: no cover - ì´ˆê¸°í™” ì‹¤íŒ¨ëŠ” ì‚¬ìš©ì í™˜ê²½ ë¬¸ì œ
        raise RuntimeError(f"ForgeMode ì´ˆê¸°í™” ì‹¤íŒ¨: {exc}") from exc

    system_info = ask_mode.get_system_info()
    textbook_structure = get_textbook_structure()

    return ask_mode, forge_mode, system_info, textbook_structure, logger


def init_session_state() -> None:
    """í•„ìš”í•œ ì„¸ì…˜ ìƒíƒœ í‚¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""

    if "messages" not in st.session_state:
        st.session_state.messages: List[Dict[str, Any]] = []
    if "ui_mode" not in st.session_state:
        st.session_state.ui_mode = "Ask"
    if "forge_results" not in st.session_state:
        st.session_state.forge_results: List[Dict[str, Any]] = []
    if "forge_generated_mcqs" not in st.session_state:
        st.session_state.forge_generated_mcqs: List[Dict[str, Any]] = []
    if "forge_feedback" not in st.session_state:
        st.session_state.forge_feedback: Optional[str] = None


def reset_forge_state() -> None:
    """Forge ëª¨ë“œ ê´€ë ¨ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""

    st.session_state.forge_results = []
    st.session_state.forge_generated_mcqs = []
    st.session_state.forge_feedback = None


def render_sidebar(system_info: Dict[str, Any]) -> None:
    """ì‚¬ì´ë“œë°” UIë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""

    st.sidebar.header("ì˜µì…˜")
    sidebar_mode = st.sidebar.selectbox(
        "ëª¨ë“œ",
        options=("Ask", "Forge"),
        index=0 if st.session_state.ui_mode == "Ask" else 1,
        key="sidebar_mode_selector",
    )
    if sidebar_mode != st.session_state.ui_mode:
        st.session_state.ui_mode = sidebar_mode
        st.session_state.messages = []
        reset_forge_state()
        st.rerun()

    if st.sidebar.button("ëŒ€í™”/ê²°ê³¼ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        reset_forge_state()
        st.sidebar.success("ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")

    st.sidebar.divider()
    st.sidebar.header("ì‹œìŠ¤í…œ ì •ë³´")
    st.sidebar.caption("í˜„ì¬ Vertex AI Â· LangGraph êµ¬ì„±ì„ ìš”ì•½í•©ë‹ˆë‹¤.")
    try:
        st.sidebar.json(system_info, expanded=False)
    except TypeError:
        st.sidebar.write(system_info)


def render_source_documents(sources: List[Dict[str, Any]]) -> None:
    """ì‘ë‹µì— í¬í•¨ëœ ì°¸ê³  ë¬¸ì„œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""

    if not sources:
        return

    st.markdown("**ğŸ“š ì°¸ê³  ë¬¸ì„œ**")
    for idx, doc in enumerate(sources, 1):
        metadata = doc.get("metadata", {})
        title = metadata.get("title") or metadata.get("doc_title") or metadata.get("source")
        part = metadata.get("part") or metadata.get("chapter")
        page = metadata.get("page_number")
        segments = []
        if title:
            segments.append(title)
        if part:
            segments.append(str(part))
        if page is not None:
            segments.append(f"p.{page}")

        header = " Â· ".join(segments) if segments else "ë¬¸ì„œ"
        st.markdown(f"{idx}. {header}")


def save_mcqs_to_txt(mcqs: List[Dict[str, Any]], topic_name: str) -> str:
    """ìƒì„±ëœ MCQë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"mcq_{topic_name}_{timestamp}.txt"
    output_dir = Path("Data") / "Result"
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / filename

    with open(output_path, "w", encoding="utf-8") as file:
        file.write("=" * 70 + "\n")
        file.write("MCQ ìƒì„± ê²°ê³¼\n")
        file.write(f"ì£¼ì œ: {topic_name}\n")
        file.write(f"ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        file.write(f"ì´ ë¬¸ì œ ìˆ˜: {len(mcqs)}ê°œ\n")
        file.write("=" * 70 + "\n\n")

        for idx, mcq in enumerate(mcqs, 1):
            file.write(f"[ë¬¸ì œ {idx}]\n")
            file.write("-" * 70 + "\n\n")
            file.write(f"ì§ˆë¬¸: {mcq.get('question', 'N/A')}\n\n")

            for option_idx, option in enumerate(mcq.get("options", []), 1):
                file.write(f"{option_idx}. {option}\n")

            file.write(f"\nâœ… ì •ë‹µ: {mcq.get('answer_index', 0)}ë²ˆ\n\n")

            explanation = mcq.get("explanation", [])
            if explanation:
                file.write("ğŸ“– í•´ì„¤:\n")
                if isinstance(explanation, list):
                    for exp_idx, exp in enumerate(explanation, 1):
                        if exp and exp.strip():
                            file.write(f"  {exp_idx}ë²ˆ: {exp}\n")
                else:
                    file.write(f"  {explanation}\n")
                file.write("\n")

            title = mcq.get("doc_title", "N/A")
            part = mcq.get("selected_part", "N/A")
            chapter = mcq.get("selected_chapter", "N/A")
            file.write(f"ğŸ“‹ ì¶œì²˜: {title} - {part} - {chapter}\n")
            file.write("\n" + "=" * 70 + "\n\n")

    return str(output_path)


def is_duplicate_mcq(
    new_mcq: Dict[str, Any],
    existing_mcqs: List[Dict[str, Any]],
    similarity_threshold: float = 0.8,
) -> bool:
    """ìƒˆë¡œ ìƒì„±í•œ MCQê°€ ê¸°ì¡´ í•­ëª©ê³¼ ì¤‘ë³µì¸ì§€ ê²€ì‚¬í•©ë‹ˆë‹¤."""

    new_question = new_mcq.get("question", "").strip().lower()
    new_options = new_mcq.get("options", [])
    new_chapter = new_mcq.get("selected_chapter", "")

    new_content = new_question + " " + " ".join(opt.strip().lower() for opt in new_options)

    same_chapter_mcqs = []
    if new_chapter:
        same_chapter_mcqs = [
            mcq for mcq in existing_mcqs if mcq.get("selected_chapter", "") == new_chapter
        ]
    chapter_threshold = 0.75 if same_chapter_mcqs else similarity_threshold

    for existing_mcq in existing_mcqs:
        existing_question = existing_mcq.get("question", "").strip().lower()
        existing_options = existing_mcq.get("options", [])

        if new_question == existing_question:
            return True

        existing_content = (
            existing_question + " " + " ".join(opt.strip().lower() for opt in existing_options)
        )
        current_threshold = (
            chapter_threshold
            if existing_mcq.get("selected_chapter", "") == new_chapter
            else similarity_threshold
        )

        shorter = min(len(new_content), len(existing_content))
        if shorter == 0:
            continue

        common_chars = sum(1 for a, b in zip(new_content, existing_content) if a == b)
        similarity = common_chars / shorter

        if similarity >= current_threshold:
            return True

        new_options_lower = [opt.strip().lower() for opt in new_options]
        existing_options_lower = [opt.strip().lower() for opt in existing_options]
        matching_options = sum(1 for opt in new_options_lower if opt in existing_options_lower)
        if matching_options >= 3:
            return True

    return False


def allocate_questions_by_distribution(num_questions: int, weights: Dict[str, float]) -> List[str]:
    """ê°€ì¤‘ì¹˜ì— ë”°ë¼ í•­ëª©ì„ ê²°ì •ë¡ ì ìœ¼ë¡œ ë°°ë¶„í•©ë‹ˆë‹¤."""

    if not weights or num_questions <= 0:
        return []

    total_weight = sum(weights.values())
    if total_weight == 0:
        return []

    allocations: Dict[str, int] = {}
    fractional_parts: Dict[str, float] = {}

    for name, weight in weights.items():
        count = (weight / total_weight) * num_questions
        integer_part = int(count)
        allocations[name] = integer_part
        fractional_parts[name] = count - integer_part

    total_allocated = sum(allocations.values())
    remaining = num_questions - total_allocated

    if remaining > 0:
        sorted_by_fraction = sorted(
            fractional_parts.items(), key=lambda item: item[1], reverse=True
        )
        for idx in range(remaining):
            name = sorted_by_fraction[idx][0]
            allocations[name] += 1

    result: List[str] = []
    for name, count in allocations.items():
        result.extend([name] * count)

    random.shuffle(result)
    return result


def build_filtered_structure(
    topic_key: str, topic_type: str, textbook_structure: Dict[str, List[str]]
) -> Dict[str, List[str]]:
    """ìš”ì²­ëœ ë²”ìœ„ë¥¼ ForgeMode ì…ë ¥ êµ¬ì¡°ì— ë§ê²Œ ë³€í™˜í•©ë‹ˆë‹¤."""

    if topic_type == "part":
        if topic_key not in textbook_structure:
            raise ValueError(f"'{topic_key}' ë²”ìœ„ë¥¼ êµì¬ êµ¬ì¡°ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {topic_key: textbook_structure[topic_key]}

    if topic_type == "chapter":
        for part, chapters in textbook_structure.items():
            if topic_key in chapters:
                return {part: [topic_key]}
        raise ValueError(f"'{topic_key}' ì±•í„°ë¥¼ êµì¬ êµ¬ì¡°ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    raise ValueError("Mock Examì€ ë³„ë„ ì²˜ë¦¬ ëŒ€ìƒì…ë‹ˆë‹¤.")


def parse_forge_request(text: str) -> Optional[Dict[str, Any]]:
    """ìì—°ì–´ ì…ë ¥ì—ì„œ Forge ìš”ì²­ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""

    normalized = re.sub(r"\s+", "", text.lower())

    topic_key: Optional[str] = None
    for key, aliases in FORGE_TOPIC_ALIASES.items():
        if any(alias in normalized for alias in aliases):
            topic_key = key
            break

    if topic_key is None:
        return None

    count_match = re.search(r"(\d+)", text)
    count = int(count_match.group(1)) if count_match else 1
    count = max(1, min(50, count))

    topic_type = FORGE_TOPIC_TYPES.get(topic_key, "part")
    if topic_type == "mock_exam":
        count = 40

    return {
        "topic_key": topic_key,
        "topic_type": topic_type,
        "count": count,
        "display_name": FORGE_TOPIC_DISPLAY_NAMES.get(topic_key, topic_key),
    }


def display_mcq(mcq: Dict[str, Any], index: int) -> None:
    """Streamlit ì»´í¬ë„ŒíŠ¸ë¡œ MCQë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""

    st.markdown(f"**ë¬¸ì œ {index}. {mcq.get('question', 'N/A')}**")
    options = mcq.get("options", [])
    if options:
        st.markdown("\n".join([f"{idx}. {opt}" for idx, opt in enumerate(options, 1)]))

    st.markdown(f"âœ… **ì •ë‹µ:** {mcq.get('answer_index', 0)}ë²ˆ")

    explanation = mcq.get("explanation", [])
    if explanation:
        st.markdown("ğŸ“– **í•´ì„¤**")
        if isinstance(explanation, list):
            for idx, exp in enumerate(explanation, 1):
                if exp and exp.strip():
                    st.markdown(f"- {idx}ë²ˆ: {exp}")
        else:
            st.markdown(f"- {explanation}")

    title = mcq.get("doc_title", "N/A")
    part = mcq.get("selected_part", "N/A")
    chapter = mcq.get("selected_chapter", "N/A")
    st.caption(f"ğŸ“‹ ì¶œì²˜: {title} Â· {part} Â· {chapter}")


def record_forge_result(
    request_text: str,
    title: str,
    mcqs: List[Dict[str, Any]],
    file_path: str,
    warnings: Optional[List[str]] = None,
) -> None:
    """ì„¸ì…˜ ìƒíƒœì— Forge ìƒì„± ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""

    st.session_state.forge_generated_mcqs.extend(mcqs)
    st.session_state.forge_results.insert(
        0,
        {
            "request": request_text,
            "title": title,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "mcqs": mcqs,
            "file_path": file_path,
            "warnings": warnings or [],
        },
    )


def handle_mock_exam_request(
    request_text: str,
    forge_mode: ForgeMode,
    textbook_structure: Dict[str, List[str]],
    logger,
) -> None:
    """ë™í˜• ëª¨ì˜ê³ ì‚¬ 40ë¬¸ì œë¥¼ ìƒì„±í•˜ê³  ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""

    config = get_mcq_generation_config()
    chapter_weights_flat: Dict[str, float] = {}
    for part, chapters in config.get("chapter_weights", {}).items():
        for chapter, weight in chapters.items():
            chapter_weights_flat[chapter] = weight

    chapter_allocation = allocate_questions_by_distribution(40, chapter_weights_flat)
    allocation_summary = Counter(chapter_allocation)

    st.markdown("#### ğŸ“‹ Chapter í• ë‹¹ ê²°ê³¼")
    for chapter, count in sorted(allocation_summary.items()):
        st.markdown(f"- {chapter}: {count}ë¬¸ì œ")

    status_container = st.container()
    progress_bar = st.progress(0)
    logs: List[str] = []
    generated_mcqs: List[Dict[str, Any]] = []
    retry_limit = 10

    for index, selected_chapter in enumerate(chapter_allocation, 1):
        progress_bar.progress(index / 40)
        chapter_weights = get_category_weights_by_topic(selected_chapter)
        retry_count = 0
        while retry_count < retry_limit:
            try:
                mcq = forge_mode.generate_mcq(
                    topics_hierarchical=textbook_structure,
                    topics_nested=None,
                    user_topic=selected_chapter,
                    max_retries=6,
                    category_weights=chapter_weights,
                )
            except Exception as exc:
                logger.error(f"ë™í˜•ëª¨ì˜ê³ ì‚¬ [{index}] ì‹¤íŒ¨: {exc}")
                logs.append(f"[{index}/40] âŒ {selected_chapter}: {exc}")
                break

            if mcq and not is_duplicate_mcq(mcq, generated_mcqs):
                generated_mcqs.append(mcq)
                logs.append(f"[{index}/40] âœ… {selected_chapter} ë¬¸ì œ ìƒì„± ì™„ë£Œ")
                break

            retry_count += 1
            logs.append(
                f"[{index}/40] ğŸ”„ {selected_chapter} ì¤‘ë³µ ê°ì§€, ì¬ì‹œë„ ({retry_count}/{retry_limit})"
            )

        if retry_count >= retry_limit:
            logs.append(f"[{index}/40] âš ï¸ {selected_chapter} ì¤‘ë³µ ë°©ì§€ ì‹¤íŒ¨")

        status_container.markdown("\n".join(logs))

    progress_bar.progress(1.0)

    if not generated_mcqs:
        st.warning("ìƒì„±ëœ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        return

    file_path = save_mcqs_to_txt(generated_mcqs, "ë™í˜•ëª¨ì˜ê³ ì‚¬_40ë¬¸ì œ")
    record_forge_result(
        request_text=request_text,
        title="ë™í˜•ëª¨ì˜ê³ ì‚¬ 40ë¬¸ì œ",
        mcqs=generated_mcqs,
        file_path=file_path,
    )
    st.success(f"ë™í˜•ëª¨ì˜ê³ ì‚¬ ê²°ê³¼ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤: {file_path}")


def handle_forge_request(
    request_text: str,
    parsed_command: Dict[str, Any],
    forge_mode: ForgeMode,
    textbook_structure: Dict[str, List[str]],
    logger,
) -> None:
    """ì¼ë°˜ Forge ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""

    topic_key = parsed_command["topic_key"]
    topic_type = parsed_command["topic_type"]
    count = parsed_command["count"]
    display_name = parsed_command["display_name"]

    try:
        filtered_structure = build_filtered_structure(topic_key, topic_type, textbook_structure)
    except ValueError as exc:
        st.error(str(exc))
        return

    category_weights = get_category_weights_by_topic(topic_key)
    if not category_weights:
        category_weights = get_category_weights_by_topic(display_name)

    status_container = st.container()
    logs: List[str] = []
    generated_mcqs: List[Dict[str, Any]] = []
    warnings: List[str] = []
    retry_limit = 10

    with st.spinner(f"'{display_name}' ë²”ìœ„ë¡œ {count}ê°œ ë¬¸ì œ ìƒì„± ì¤‘..."):
        for index in range(1, count + 1):
            retry_count = 0
            while retry_count < retry_limit:
                try:
                    mcq = forge_mode.generate_mcq(
                        topics_hierarchical=filtered_structure,
                        topics_nested=None,
                        user_topic=topic_key if topic_type == "chapter" else None,
                        max_retries=6,
                        category_weights=category_weights if category_weights else None,
                    )
                except Exception as exc:
                    logger.error(f"Forge ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {exc}")
                    logs.append(f"[{index}/{count}] âŒ ì˜¤ë¥˜ ë°œìƒ: {exc}")
                    mcq = None
                    break

                if mcq and not is_duplicate_mcq(
                    mcq, st.session_state.forge_generated_mcqs + generated_mcqs
                ):
                    generated_mcqs.append(mcq)
                    logs.append(f"[{index}/{count}] âœ… ìƒì„± ì™„ë£Œ")
                    break

                retry_count += 1
                logs.append(
                    f"[{index}/{count}] ğŸ”„ ì¤‘ë³µ ê°ì§€, ì¬ì‹œë„ ({retry_count}/{retry_limit})"
                )

            if retry_count >= retry_limit:
                msg = f"[{index}/{count}] ì¤‘ë³µ ë°©ì§€ ì‹¤íŒ¨"
                warnings.append(msg)
                logs.append(f"[{index}/{count}] âš ï¸ ì¤‘ë³µ ë°©ì§€ ì‹¤íŒ¨")

            status_container.markdown("\n".join(logs))

    if not generated_mcqs:
        st.warning("ìƒì„±ëœ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤. ìš”ì²­ì„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return

    file_path = save_mcqs_to_txt(generated_mcqs, f"{display_name}_{len(generated_mcqs)}ê°œ")
    record_forge_result(
        request_text=request_text,
        title=f"{display_name} {len(generated_mcqs)}ë¬¸ì œ",
        mcqs=generated_mcqs,
        file_path=file_path,
        warnings=warnings,
    )

    st.success(f"ì´ {len(generated_mcqs)}ê°œ ë¬¸ì œë¥¼ ìƒì„±í•˜ê³  ì €ì¥í–ˆìŠµë‹ˆë‹¤: {file_path}")
    if warnings:
        st.warning("\n".join(warnings))


def render_forge_mode(
    forge_mode: ForgeMode,
    textbook_structure: Dict[str, List[str]],
    logger,
) -> None:
    """Forge ëª¨ë“œ UIë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""

    st.title("Forge Mode (MCQ ìƒì„±)")
    st.caption("ìì—°ì–´ë¡œ ìš”ì²­ì„ ì…ë ¥í•˜ë©´ í•´ë‹¹ ë²”ìœ„ì˜ MCQë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    st.markdown(
        "- ì˜ˆì‹œ: `ê°ë¡  5ë¬¸ì œ ë§Œë“¤ì–´ì¤˜`, `ì „ë¬¸ì™¸ìƒì²˜ì¹˜ìˆ  ë¬¸ì œ 3ê°œ`, `ë™í˜•ëª¨ì˜ê³ ì‚¬ ì‹¤í–‰`"
    )

    if st.session_state.forge_results:
        st.markdown("### ìµœê·¼ ìƒì„± ê²°ê³¼")
        for result_idx, result in enumerate(st.session_state.forge_results, 1):
            with st.expander(f"{result_idx}. {result['title']} Â· {result['timestamp']}"):
                st.caption(f"ìš”ì²­ ë¬¸ì¥: {result['request']}")
                st.caption(f"ì €ì¥ ê²½ë¡œ: `{result['file_path']}`")
                if result.get("warnings"):
                    st.warning("\n".join(result["warnings"]))
                for mcq_idx, mcq in enumerate(result["mcqs"], 1):
                    display_mcq(mcq, mcq_idx)
                    st.markdown("---")
    else:
        st.info("ì•„ì§ ìƒì„±ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ ì…ë ¥ì°½ì— ìš”ì²­ì„ ì…ë ¥í•˜ì„¸ìš”.")

    with st.form("forge_request_form", clear_on_submit=True):
        request_text = st.text_input("Forge ìš”ì²­", placeholder="ì˜ˆ) ê°ë¡  5ë¬¸ì œ ë§Œë“¤ì–´ì¤˜")
        submitted = st.form_submit_button("ë¬¸ì œ ìƒì„±")

    if submitted:
        if not request_text.strip():
            st.warning("ìš”ì²­ ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        parsed = parse_forge_request(request_text)
        if parsed is None:
            st.warning("ìš”ì²­ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë²”ìœ„ì™€ ê°œìˆ˜ë¥¼ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        if parsed["topic_type"] == "mock_exam":
            handle_mock_exam_request(request_text, forge_mode, textbook_structure, logger)
        else:
            handle_forge_request(request_text, parsed, forge_mode, textbook_structure, logger)


def render_ask_mode(ask_mode: AskMode) -> None:
    """Ask ëª¨ë“œ UIë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""

    for message in st.session_state.messages:
        role = message.get("role", "user")
        content = message.get("content", "")
        sources = message.get("sources", [])
        pipeline = message.get("pipeline", "rag")
        routing_reason = message.get("routing_reason")

        with st.chat_message(role):
            st.markdown(content)
            if role == "assistant":
                if pipeline == "rag":
                    render_source_documents(sources)
                else:
                    st.caption("ì¼ë°˜ ëŒ€í™”ë¡œ ë¶„ë¥˜ë˜ì–´ ë¬¸ì„œ ê²€ìƒ‰ ì—†ì´ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤.")
                    if routing_reason:
                        st.caption(f"íŒë‹¨ ê·¼ê±°: {routing_reason}")

    prompt = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
    if not prompt:
        return

    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                result = ask_mode.process(prompt)

            answer = result.get("answer", "")
            sources = result.get("source_documents", [])
            pipeline = result.get("pipeline", "rag")
            routing_reason = result.get("routing_reason")

            st.markdown(answer or "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            if pipeline == "rag":
                render_source_documents(sources)
            else:
                st.caption("ì¼ë°˜ ëŒ€í™”ë¡œ ë¶„ë¥˜ë˜ì–´ ë¬¸ì„œ ê²€ìƒ‰ ì—†ì´ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤.")
                if routing_reason:
                    st.caption(f"íŒë‹¨ ê·¼ê±°: {routing_reason}")

        st.session_state.messages.append(
            {
                "role": "assistant",
                "content": answer,
                "sources": sources if pipeline == "rag" else [],
                "pipeline": pipeline,
                "routing_reason": routing_reason,
            }
        )
    except Exception as exc:
        error_msg = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}"
        st.error(error_msg)
        st.session_state.messages.append(
            {
                "role": "assistant",
                "content": error_msg,
                "sources": [],
            }
        )


def main() -> None:
    st.set_page_config(page_title="Generator Dock", page_icon="ğŸ¤–", layout="wide")
    st.markdown(
        """
        <style>
        [data-testid="stChatMessage"] {
            padding: 0.75rem 0 !important;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    try:
        ask_mode, forge_mode, system_info, textbook_structure, logger = load_app_components()
    except Exception as exc:
        st.error(f"ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {exc}")
        return

    init_session_state()
    render_sidebar(system_info)

    st.divider()

    if st.session_state.ui_mode == "Forge":
        render_forge_mode(forge_mode, textbook_structure, logger)
        return

    st.title("RAG ì±—ë´‡ (Ask Mode)")
    st.write("Vertex AI Vector Searchì™€ LangGraph ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    render_ask_mode(ask_mode)


if __name__ == "__main__":
    main()


