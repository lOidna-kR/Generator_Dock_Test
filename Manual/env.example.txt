# ==================== Google Cloud 설정 ====================
# GCP 콘솔(https://console.cloud.google.com) > 프로젝트 설정에서 확인
GCP_PROJECT_ID=your-project-id-here

# 리전 설정 (예: us-central1, asia-northeast3, us-west1)
GCP_LOCATION=us-central1
GCP_REGION=us-central1

# ==================== Vertex AI 설정 ====================
# Vertex AI > Vector Search > Indexes에서 확인
# 예: 8376679913746333696
VERTEX_AI_INDEX_ID=your-index-id-here

# Vertex AI > Vector Search > Endpoints에서 확인
# 예: 1234567890123456789
VERTEX_AI_ENDPOINT_ID=your-endpoint-id-here

# Cloud Storage 버킷 이름
# 예: rag-cloud-run-test
GCS_BUCKET_NAME=your-bucket-name-here

# ==================== 모델 설정 ====================
# Gemini 모델
# 옵션: gemini-1.5-flash-002, gemini-1.5-pro-002, gemini-1.0-pro
GEMINI_MODEL_NAME=gemini-1.5-flash-002

# 임베딩 모델
# 옵션: text-embedding-004, textembedding-gecko@003
EMBEDDING_MODEL=text-embedding-004

# 임베딩 차원수 (256 ~ 768, 기본값: 768)
# text-embedding-004 모델만 output_dimensionality 파라미터를 지원합니다.
# 차원을 줄이면 성능은 약간 저하될 수 있지만, 저장 공간과 검색 속도가 개선됩니다.
EMBEDDING_DIMENSIONS=768

# ==================== Retrieval 설정 ====================
# 검색할 문서 수 (기본값: 5)
RETRIEVAL_K=5

# 검색 타입 (similarity, mmr)
SEARCH_TYPE=similarity

# 유사도 임계값 (0.0 ~ 1.0, 높을수록 엄격)
SIMILARITY_THRESHOLD=0.7

# Stream Update 사용 여부 (true/false)
STREAM_UPDATE=false

# ==================== LLM 설정 ====================
# Temperature (0.0 ~ 2.0, 낮을수록 일관적, 높을수록 창의적)
LLM_TEMPERATURE=0.7

# 최대 출력 토큰 수
MAX_OUTPUT_TOKENS=2048

# Generation Temperature (답변 생성용)
GENERATION_TEMPERATURE=0.7

# Generation 최대 토큰
GENERATION_MAX_TOKENS=2048

# ==================== 문서 처리 설정 ====================
# 청크 크기 (토큰 단위)
CHUNK_SIZE=1000

# 청크 오버랩 (토큰 단위)
CHUNK_OVERLAP=200

# ==================== 출력 설정 ====================
# 출처 문서 미리보기 최대 길이 (문자 수)
MAX_SOURCE_PREVIEW=300

# ==================== 로깅 설정 ====================
# 로그 레벨 (DEBUG, INFO, WARNING, ERROR, CRITICAL)
# - DEBUG: 상세한 디버깅 정보 (개발 환경)
# - INFO: 일반 정보 메시지 (프로덕션 권장)
# - WARNING: 경고 메시지
# - ERROR: 에러 메시지
# - CRITICAL: 치명적 오류
LOG_LEVEL=INFO

# 콘솔 로깅 사용 여부 (true/false)
LOG_CONSOLE=true

# 파일 로깅 사용 여부 (true/false)
# 로그 파일은 Logs/ 폴더에 저장됩니다 (예: Logs/generator_20250123.log)
# 기본값: true (파일 로깅 활성화)
LOG_FILE=true

# ==================== 인증 설정 ====================
# Google Cloud 서비스 계정 키 파일 경로 (절대 경로)
# GCP 콘솔 > IAM > 서비스 계정 > 키 생성 (JSON)
# Windows 예시: C:/keys/service-account-key.json
# Linux/Mac 예시: /home/user/keys/service-account-key.json
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json

# ==================== MCQ 생성 설정 ====================
# Few-shot 예시가 있는 폴더 경로
MCQ_FEW_SHOT_FOLDER_PATH=Data/Few_Shot

# Few-shot 예시 최대 사용 개수 (프롬프트에 포함할 예시 수)
MCQ_FEW_SHOT_MAX_EXAMPLES=3

# 랜덤 문서 샘플링 최대 개수
MCQ_RANDOM_SAMPLE_MAX=1000

# ==================== MCQ Part 가중치 설정 ====================
# Part별 문제 생성 비율은 config.py에서 설정됩니다.
# 현재 설정 (교재 비중 반영):
#   - Part 01: 전문응급처치학 총론: 20% (기초 이론)
#   - Part 02: 의료/법적 책임: 10% (법규)
#   - Part 03: 전문응급처치학 각론: 70% (실무, 가장 많은 내용)
# 
# 가중치를 변경하려면 config.py의 get_mcq_generation_config() 함수를 수정하세요.

# ==================== 선택적 설정 ====================
# 데이터베이스 URL (필요 시)
# DATABASE_URL=postgresql://user:password@localhost/db

# API Secret Key (필요 시)
# SECRET_KEY=your-secret-key-here

# 캐시 TTL (초 단위, 필요 시)
# CACHE_TTL_SECONDS=3600

# ==================== 사용 방법 ====================
# 1. 이 파일을 .env로 이름 변경
#    Windows: ren env.example.txt .env
#    Linux/Mac: mv env.example.txt .env
#
# 2. 위의 값들을 실제 값으로 수정
#
# 3. .env 파일이 .gitignore에 포함되어 있는지 확인
#    cat .gitignore | grep .env

